
## how to do filters
from pyspark.sql.functions import col
# join empDF ,deptData and addData
mainDF=empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id).join(addDF,empDF.emp_id==addDF.emp_id)\
.select(empDF.emp_id.alias("emp_name"),addDF.emp_id,empDF.name,deptDF.dept_name,addDF.addline1,addDF.city)\
.filter( (addDF.state  == "CA") & (addDF.city  == "SFO") ) 
mainDF.show()

print(pivoteentitlementdf.select(pivoteentitlementdf["entitlement_id"]).distinct().count())
##
from pyspark.sql.functions import distinct

distinct number and count 
## print count of unique pivoteentitlementdf values and show the table result aswell 
pivoteentitlementdf.select(pivoteentitlementdf["INDEPENT PRES"]).distinct().count()




if len(mainDF.columns)>2 and len(mainDF.columns)<5:
    print("good")
else:
    print("data frame lenght is bad")
if mainDF.select(mainDF.emp_id).distinct().count()==1:
    print("good")
elif mainDF.select(mainDF.emp_id).distinct().count()>1:
    print("bad")
elif mainDF.select(mainDF.emp_id).distinct().count()<1:
    print("bad")
if mainDF.select(mainDF.dept_name).distinct().count()==1:
    print("good")
elif mainDF.select(mainDF.dept_name).distinct().count()>1:
    print("bad")
elif mainDF.select(mainDF.dept_name).distinct().count()<1:
    print("bad")
    
    
    
    columns_name=mainDF1.columns

if columns_name == addDF2.columns:
    print("Columns matched")
else:
    print("Columns not matched")
    print("Columns not matched are:")
    for i in columns_name:
        if i not in addDF2.columns:  # if i not in mainDF1.columns then print i else print nothing 
            print(i)


    
    
    
    
    
    # combine two backslash and code comment\
mainDF=(empDF.join( deptDF,empDF.emp_dept_id==deptDF.dept_id).join(addDF,empDF.emp_id==addDF.emp_id) # this is to join empDF ,deptData and addData
.select(empDF.emp_id.alias("emp_name"),addDF.emp_id,empDF.name,deptDF.dept_name,addDF.addline1,addDF.city) # this is to select the columns
.filter( (addDF.state  == "CA") & (addDF.city  == "SFO"))                                       # this is to filter the data
)
mainDF.show()


